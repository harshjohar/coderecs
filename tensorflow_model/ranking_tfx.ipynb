{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjUA6S30k52h"
   },
   "source": [
    "##### Copyright 2022 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>ID</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akshaygahlot73</td>\n",
       "      <td>131689</td>\n",
       "      <td>2</td>\n",
       "      <td>284477248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akshaygahlot73</td>\n",
       "      <td>129692</td>\n",
       "      <td>6</td>\n",
       "      <td>284477248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akshaygahlot73</td>\n",
       "      <td>129689</td>\n",
       "      <td>7</td>\n",
       "      <td>284477248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akshaygahlot73</td>\n",
       "      <td>129052</td>\n",
       "      <td>4</td>\n",
       "      <td>284477248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akshaygahlot73</td>\n",
       "      <td>129130</td>\n",
       "      <td>7</td>\n",
       "      <td>284477248865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883939</th>\n",
       "      <td>shubhamgupta.62000</td>\n",
       "      <td>108892</td>\n",
       "      <td>10</td>\n",
       "      <td>2311063523943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883940</th>\n",
       "      <td>shubhamgupta.62000</td>\n",
       "      <td>112720</td>\n",
       "      <td>9</td>\n",
       "      <td>2311063523943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883941</th>\n",
       "      <td>shubhamgupta.62000</td>\n",
       "      <td>109920</td>\n",
       "      <td>2</td>\n",
       "      <td>2311063523943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883942</th>\n",
       "      <td>shubhamgupta.62000</td>\n",
       "      <td>18163</td>\n",
       "      <td>10</td>\n",
       "      <td>2311063523943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883943</th>\n",
       "      <td>shubhamgupta.62000</td>\n",
       "      <td>54403</td>\n",
       "      <td>10</td>\n",
       "      <td>2311063523943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4883944 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   username      ID  rating        user_id\n",
       "0            akshaygahlot73  131689       2   284477248865\n",
       "1            akshaygahlot73  129692       6   284477248865\n",
       "2            akshaygahlot73  129689       7   284477248865\n",
       "3            akshaygahlot73  129052       4   284477248865\n",
       "4            akshaygahlot73  129130       7   284477248865\n",
       "...                     ...     ...     ...            ...\n",
       "4883939  shubhamgupta.62000  108892      10  2311063523943\n",
       "4883940  shubhamgupta.62000  112720       9  2311063523943\n",
       "4883941  shubhamgupta.62000  109920       2  2311063523943\n",
       "4883942  shubhamgupta.62000   18163      10  2311063523943\n",
       "4883943  shubhamgupta.62000   54403      10  2311063523943\n",
       "\n",
       "[4883944 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/TFRS-ranking/ratings.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:03.665121Z",
     "iopub.status.busy": "2022-03-30T11:15:03.664861Z",
     "iopub.status.idle": "2022-03-30T11:15:03.669176Z",
     "shell.execute_reply": "2022-03-30T11:15:03.668492Z"
    },
    "id": "SpNWyqewk8fE"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1ypzczQCwy"
   },
   "source": [
    "# Using TensorFlow Recommenders with TFX\n",
    "\n",
    "***A tutorial to train a TensorFlow Recommenders ranking model as a [TFX pipeline](https://www.tensorflow.org/tfx).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/TFRS-ranking/ratings.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU9YYythm0dx"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/ranking_tfx\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VuwrlnvQJ5k"
   },
   "source": [
    "In this notebook-based tutorial, we will create and run a [TFX pipeline](https://www.tensorflow.org/tfx)\n",
    "to train a ranking model to predict movie ratings using TensorFlow Recommenders (TFRS).\n",
    "The pipeline will consist of three essential TFX components: ExampleGen,\n",
    "Trainer and Pusher. The pipeline includes the most minimal ML workflow like\n",
    "importing data, training a model and exporting the trained TFRS ranking model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fmgi8ZvQkScg"
   },
   "source": [
    "## Set Up\n",
    "We first need to install the TFX Python package and download\n",
    "the dataset which we will use for our model.\n",
    "\n",
    "### Upgrade Pip\n",
    "\n",
    "To avoid upgrading Pip in a system when running locally,\n",
    "check to make sure that we are running in Colab.\n",
    "Local systems can of course be upgraded separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:03.672628Z",
     "iopub.status.busy": "2022-03-30T11:15:03.672128Z",
     "iopub.status.idle": "2022-03-30T11:15:03.678415Z",
     "shell.execute_reply": "2022-03-30T11:15:03.677872Z"
    },
    "id": "as4OTe2ukSqm"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZOYTt1RW4TK"
   },
   "source": [
    "### Install TFX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:03.681563Z",
     "iopub.status.busy": "2022-03-30T11:15:03.680940Z",
     "iopub.status.idle": "2022-03-30T11:15:10.423670Z",
     "shell.execute_reply": "2022-03-30T11:15:10.422877Z"
    },
    "id": "iyQtljP-qPHY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfx\n",
      "  Using cached tfx-1.9.0-py3-none-any.whl (2.5 MB)\n",
      "Collecting click<8,>=7\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting tensorflow-model-analysis<0.41,>=0.40.0\n",
      "  Using cached tensorflow_model_analysis-0.40.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting ml-pipelines-sdk==1.9.0\n",
      "  Using cached ml_pipelines_sdk-1.9.0-py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: pyyaml<6,>=3.12 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (5.4.1)\n",
      "Collecting google-api-python-client<2,>=1.8\n",
      "  Using cached google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5\n",
      "  Using cached tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "Requirement already satisfied: google-api-core<2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (1.30.0)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (1.19.5)\n",
      "Collecting google-apitools<1,>=0.5\n",
      "  Using cached google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
      "Collecting tensorflow-data-validation<1.10.0,>=1.9.0\n",
      "  Using cached tensorflow_data_validation-1.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.5 MB)\n",
      "Collecting kubernetes<13,>=10.0.1\n",
      "  Using cached kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-transform<1.10.0,>=1.9.0\n",
      "  Using cached tensorflow_transform-1.9.0-py3-none-any.whl (436 kB)\n",
      "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15\n",
      "  Using cached tensorflow_serving_api-2.9.1-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: packaging<21,>=20 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (20.9)\n",
      "Requirement already satisfied: grpcio<2,>=1.28.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (1.34.1)\n",
      "Collecting docker<5,>=4.1\n",
      "  Using cached docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.9.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (0.12.0)\n",
      "Collecting jinja2<4,>=2.7.3\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m210.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (3.14.0)\n",
      "Collecting attrs<21,>=19.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting portpicker<2,>=1.3.1\n",
      "  Using cached portpicker-1.5.2-py3-none-any.whl (14 kB)\n",
      "Collecting tfx-bsl<1.10.0,>=1.9.0\n",
      "  Using cached tfx_bsl-1.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (19.2 MB)\n",
      "Collecting ml-metadata<1.10.0,>=1.9.0\n",
      "  Using cached ml_metadata-1.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Collecting google-cloud-aiplatform<2,>=1.6.2\n",
      "  Using cached google_cloud_aiplatform-1.15.0-py2.py3-none-any.whl (2.1 MB)\n",
      "Collecting typing-extensions<5,>=3.10.0.2\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (0.12.0)\n",
      "Requirement already satisfied: pyarrow<6,>=1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tfx) (3.0.0)\n",
      "Collecting google-cloud-bigquery<3,>=2.26.0\n",
      "  Using cached google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "Collecting apache-beam[gcp]<3,>=2.38\n",
      "  Using cached apache_beam-2.40.0-cp39-cp39-manylinux2010_x86_64.whl (12.0 MB)\n",
      "Collecting keras-tuner<2,>=1.0.4\n",
      "  Using cached keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: six in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from absl-py<2.0.0,>=0.9->tfx) (1.15.0)\n",
      "Collecting orjson<4.0\n",
      "  Using cached orjson-3.7.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Collecting cloudpickle<3,>=2.1.0\n",
      "  Using cached cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (0.3.1.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (3.11.4)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (2021.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.18.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (2.6.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.7)\n",
      "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (0.19.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5,>=3.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (4.2.2)\n",
      "Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.6.0)\n",
      "Collecting google-cloud-bigtable<2,>=0.31.1\n",
      "  Downloading google_cloud_bigtable-1.7.2-py2.py3-none-any.whl (267 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.7/267.7 kB\u001b[0m \u001b[31m714.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n",
      "  Downloading google_cloud_vision-1.0.2-py2.py3-none-any.whl (435 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.1/435.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-apitools<1,>=0.5\n",
      "  Using cached google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (0.1.0)\n",
      "Collecting google-cloud-datastore<2,>=1.8.0\n",
      "  Downloading google_cloud_datastore-1.15.5-py2.py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-pubsublite<2,>=1.2.0\n",
      "  Downloading google_cloud_pubsublite-1.4.2-py2.py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.8/265.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-spanner<2,>=1.13.0\n",
      "  Downloading google_cloud_spanner-1.19.3-py2.py3-none-any.whl (255 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-language<2,>=1.3.0\n",
      "  Downloading google_cloud_language-1.3.2-py2.py3-none-any.whl (83 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-pubsub<3,>=2.1.0\n",
      "  Downloading google_cloud_pubsub-2.13.4-py2.py3-none-any.whl (234 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.4/234.4 kB\u001b[0m \u001b[31m710.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m759.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[gcp]<3,>=2.38->tfx) (1.30.1)\n",
      "Collecting grpcio-gcp<1,>=0.2.2\n",
      "  Using cached grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Collecting google-cloud-recommendations-ai<=0.2.0,>=0.1.0\n",
      "  Downloading google_cloud_recommendations_ai-0.2.0-py2.py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-bigquery-storage>=2.6.3\n",
      "  Downloading google_cloud_bigquery_storage-2.14.1-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m531.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-dlp<4,>=3.0.0\n",
      "  Downloading google_cloud_dlp-3.7.1-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.2/118.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-videointelligence<2,>=1.8.0\n",
      "  Downloading google_cloud_videointelligence-1.16.3-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m905.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core<2->tfx) (52.0.0.post20210125)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core<2->tfx) (1.53.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-python-client<2,>=1.8->tfx) (3.0.1)\n",
      "Collecting fasteners>=0.14\n",
      "  Downloading fasteners-0.17.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-apitools<1,>=0.5->tfx) (4.1.3)\n",
      "Collecting protobuf<4,>=3.13\n",
      "  Using cached protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m329.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.6.0-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.2/231.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.4.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-cloud-bigquery<3,>=2.26.0->tfx) (1.3.0)\n",
      "Collecting grpcio<2,>=1.28.1\n",
      "  Using cached grpcio-1.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: ipython in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from keras-tuner<2,>=1.0.4->tfx) (8.3.0)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: tensorboard in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from keras-tuner<2,>=1.0.4->tfx) (2.5.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kubernetes<13,>=10.0.1->tfx) (1.26.4)\n",
      "Requirement already satisfied: requests-oauthlib in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from kubernetes<13,>=10.0.1->tfx) (2022.6.15)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from packaging<21,>=20->tfx) (2.4.7)\n",
      "Requirement already satisfied: psutil in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from portpicker<2,>=1.3.1->tfx) (5.8.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (1.1.2)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (3.1.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting absl-py<2.0.0,>=0.9\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting protobuf<4,>=3.13\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (0.2.0)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting numpy<2,>=1.16\n",
      "  Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (1.6.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyfarmhash<0.4,>=0.2\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m264.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m272.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting joblib<0.15,>=0.12\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m898.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m998.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.10,>=1.9.0\n",
      "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m743.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<2,>=1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-data-validation<1.10.0,>=1.9.0->tfx) (1.2.4)\n",
      "Requirement already satisfied: scipy<2,>=1.4.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-model-analysis<0.41,>=0.40.0->tfx) (1.6.2)\n",
      "Collecting ipywidgets<8,>=7\n",
      "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m916.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting ipython\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5->tfx) (0.36.2)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.8.0-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m294.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.7.3-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m329.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.7.2-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m340.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.7.1-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m341.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.7.0-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m367.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.6.1-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m380.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.6.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m385.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.5.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m456.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m500.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.4.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m221.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m219.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_api_core-2.3.2-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m26.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m310.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Using cached google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.38->tfx) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.38->tfx) (0.2.8)\n",
      "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
      "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio-status>=1.16.0\n",
      "  Downloading grpcio_status-1.47.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting overrides<7.0.0,>=6.0.1\n",
      "  Downloading overrides-6.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m369.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "  Downloading google_cloud_storage-2.3.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m330.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading google_cloud_storage-2.2.1-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m297.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (1.1.2)\n",
      "Requirement already satisfied: docopt in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.38->tfx) (0.6.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (3.0.20)\n",
      "Requirement already satisfied: pickleshare in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (0.1.2)\n",
      "Requirement already satisfied: backcall in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (5.1.1)\n",
      "Requirement already satisfied: pygments in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython->keras-tuner<2,>=1.0.4->tfx) (2.11.2)\n",
      "Collecting ipython-genutils~=0.2.0\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (6.9.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m321.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m304.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m308.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.38->tfx) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.38->tfx) (3.0.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (1.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard->keras-tuner<2,>=1.0.4->tfx) (3.3.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (1.14.5)\n",
      "Collecting googleapis-common-protos[grpc]<2.0.0dev,>=1.56.0\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m291.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m297.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client<8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (7.2.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (6.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (1.5.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jedi>=0.16->ipython->keras-tuner<2,>=1.0.4->tfx) (0.8.3)\n",
      "Collecting typing-utils>=0.0.3\n",
      "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pexpect>4.3->ipython->keras-tuner<2,>=1.0.4->tfx) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner<2,>=1.0.4->tfx) (0.2.5)\n",
      "Collecting notebook>=4.4.1\n",
      "  Downloading notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m235.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3,>=2.26.0->tfx) (2.20)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (22.3.0)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (4.10.0)\n",
      "Requirement already satisfied: entrypoints in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.41,>=0.40.0->tfx) (0.4)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.15.0-py3-none-any.whl (16 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Collecting nbconvert>=5\n",
      "  Using cached nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
      "Collecting nbformat\n",
      "  Downloading nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m208.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting tinycss2\n",
      "  Using cached tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.6.6-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m187.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m223.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.16.1-py3-none-any.whl (22 kB)\n",
      "Collecting jsonschema>=2.6\n",
      "  Downloading jsonschema-4.7.2-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m229.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Using cached pyrsistent-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m629.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: google-apitools, pyfarmhash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131041 sha256=5348e70752c215a00168565ab0d4ac9d0f6440beec9ab9fd36d2fac89a671cdb\n",
      "  Stored in directory: /home/padma/.cache/pip/wheels/6c/f8/60/b9e91899dbaf25b6314047d3daee379bdd8d61b1dc3fd5ec7f\n",
      "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp39-cp39-linux_x86_64.whl size=14328 sha256=5d7d8e136d2f548fd952bb5507996d526ac21deb7d3462cfc84c61c5caed18fc\n",
      "  Stored in directory: /home/padma/.cache/pip/wheels/de/2b/b1/c541160670d70f4b08c4786f4e155337d4baeaa3e01d9d1400\n",
      "Successfully built google-apitools pyfarmhash\n",
      "Installing collected packages: webencodings, Send2Trash, pyfarmhash, mistune, libclang, kt-legacy, keras, joblib, ipython-genutils, fastjsonschema, websocket-client, typing-utils, typing-extensions, traitlets, tinycss2, terminado, tensorflow-io-gcs-filesystem, tensorflow-estimator, soupsieve, pyrsistent, protobuf, prometheus-client, portpicker, pandocfilters, orjson, numpy, MarkupSafe, jupyterlab-widgets, jupyterlab-pygments, grpcio, fasteners, defusedxml, cloudpickle, click, bleach, attrs, absl-py, overrides, ml-metadata, jsonschema, jinja2, grpcio-gcp, googleapis-common-protos, docker, beautifulsoup4, argon2-cffi-bindings, tensorflow-metadata, nbformat, kubernetes, ipython, grpcio-status, google-resumable-media, google-apitools, google-api-core, argon2-cffi, apache-beam, tensorboard, nbclient, grpc-google-iam-v1, google-api-python-client, tensorflow, nbconvert, ml-pipelines-sdk, keras-tuner, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-resource-manager, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-language, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery, tensorflow-serving-api, notebook, google-cloud-pubsublite, google-cloud-aiplatform, widgetsnbextension, tfx-bsl, ipywidgets, tensorflow-transform, tensorflow-model-analysis, tensorflow-data-validation, tfx\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.14.0\n",
      "    Uninstalling protobuf-3.14.0:\n",
      "      Successfully uninstalled protobuf-3.14.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.1\n",
      "    Uninstalling click-8.0.1:\n",
      "      Successfully uninstalled click-8.0.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.53.0\n",
      "    Uninstalling googleapis-common-protos-1.53.0:\n",
      "      Successfully uninstalled googleapis-common-protos-1.53.0\n",
      "  Attempting uninstall: tensorflow-metadata\n",
      "    Found existing installation: tensorflow-metadata 1.0.0\n",
      "    Uninstalling tensorflow-metadata-1.0.0:\n",
      "      Successfully uninstalled tensorflow-metadata-1.0.0\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.3.0\n",
      "    Uninstalling ipython-8.3.0:\n",
      "      Successfully uninstalled ipython-8.3.0\n",
      "  Attempting uninstall: google-resumable-media\n",
      "    Found existing installation: google-resumable-media 1.3.0\n",
      "    Uninstalling google-resumable-media-1.3.0:\n",
      "      Successfully uninstalled google-resumable-media-1.3.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.30.0\n",
      "    Uninstalling google-api-core-1.30.0:\n",
      "      Successfully uninstalled google-api-core-1.30.0\n",
      "  Attempting uninstall: apache-beam\n",
      "    Found existing installation: apache-beam 2.30.0\n",
      "    Uninstalling apache-beam-2.30.0:\n",
      "      Successfully uninstalled apache-beam-2.30.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.8.0\n",
      "    Uninstalling google-api-python-client-2.8.0:\n",
      "      Successfully uninstalled google-api-python-client-2.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 2.20.0\n",
      "    Uninstalling google-cloud-bigquery-2.20.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-2.20.0\n",
      "Successfully installed MarkupSafe-2.1.1 Send2Trash-1.8.0 absl-py-1.1.0 apache-beam-2.40.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-20.3.0 beautifulsoup4-4.11.1 bleach-5.0.1 click-7.1.2 cloudpickle-2.1.0 defusedxml-0.7.1 docker-4.4.4 fasteners-0.17.3 fastjsonschema-2.16.1 google-api-core-1.32.0 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-aiplatform-1.15.0 google-cloud-bigquery-2.34.4 google-cloud-bigquery-storage-2.14.1 google-cloud-bigtable-1.7.2 google-cloud-datastore-1.15.5 google-cloud-dlp-3.7.1 google-cloud-language-1.3.2 google-cloud-pubsub-2.13.4 google-cloud-pubsublite-1.4.2 google-cloud-recommendations-ai-0.2.0 google-cloud-resource-manager-1.6.0 google-cloud-spanner-1.19.3 google-cloud-storage-2.2.1 google-cloud-videointelligence-1.16.3 google-cloud-vision-1.0.2 google-resumable-media-2.3.3 googleapis-common-protos-1.56.4 grpc-google-iam-v1-0.12.4 grpcio-1.47.0 grpcio-gcp-0.2.2 grpcio-status-1.47.0 ipython-7.34.0 ipython-genutils-0.2.0 ipywidgets-7.7.1 jinja2-3.1.2 joblib-0.14.1 jsonschema-4.7.2 jupyterlab-pygments-0.2.2 jupyterlab-widgets-1.1.1 keras-2.9.0 keras-tuner-1.1.3 kt-legacy-1.0.4 kubernetes-12.0.1 libclang-14.0.1 mistune-0.8.4 ml-metadata-1.9.0 ml-pipelines-sdk-1.9.0 nbclient-0.6.6 nbconvert-6.5.0 nbformat-5.4.0 notebook-6.4.12 numpy-1.22.4 orjson-3.7.7 overrides-6.1.0 pandocfilters-1.5.0 portpicker-1.5.2 prometheus-client-0.14.1 protobuf-3.19.4 pyfarmhash-0.3.2 pyrsistent-0.18.1 soupsieve-2.3.2.post1 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-data-validation-1.9.0 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflow-metadata-1.9.0 tensorflow-model-analysis-0.40.0 tensorflow-serving-api-2.9.1 tensorflow-transform-1.9.0 terminado-0.15.0 tfx-1.9.0 tfx-bsl-1.9.0 tinycss2-1.1.1 traitlets-5.3.0 typing-extensions-4.3.0 typing-utils-0.1.0 webencodings-0.5.1 websocket-client-1.3.3 widgetsnbextension-3.6.1\n",
      "Collecting tensorflow-recommenders\n",
      "  Using cached tensorflow_recommenders-0.7.0-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-recommenders) (1.1.0)\n",
      "Requirement already satisfied: tensorflow>=2.9.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow-recommenders) (2.9.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.26.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.19.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.0)\n",
      "Requirement already satisfied: packaging in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (20.9)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.47.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (52.0.0.post20210125)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.30.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from packaging->tensorflow>=2.9.0->tensorflow-recommenders) (2.4.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (2.10)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.9.0->tensorflow-recommenders) (3.1.1)\n",
      "Installing collected packages: tensorflow-recommenders\n",
      "Successfully installed tensorflow-recommenders-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tfx\n",
    "!pip install -U tensorflow-recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwT0nov5QO1M"
   },
   "source": [
    "### Did you restart the runtime?\n",
    "\n",
    "If you are using Google Colab, the first time that you run\n",
    "the cell above, you must restart the runtime by clicking\n",
    "above \"RESTART RUNTIME\" button or using \"Runtime > Restart\n",
    "runtime ...\" menu. This is because of the way that Colab\n",
    "loads packages.\n",
    "\n",
    "Before we define the pipeline, we need to write the model code for the\n",
    "Trainer component and save it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-beam[interactive] in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (2.40.0)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (0.3.1.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (3.11.4)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (2.8.2)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (2.25.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.7)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (2.1.0)\n",
      "Requirement already satisfied: orjson<4.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (3.7.7)\n",
      "Requirement already satisfied: pytz>=2018.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (2021.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.18.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (4.3.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (3.19.4)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.4.2)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.33.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.47.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (1.22.4)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (3.0.0)\n",
      "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (0.19.1)\n",
      "Collecting jupyter-client<6.1.13,>=6.1.11\n",
      "  Using cached jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: ipykernel<7,>=6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (6.9.1)\n",
      "Collecting facets-overview<2,>=1.0.0\n",
      "  Downloading facets_overview-1.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-cloud-dataproc<3.2.0,>=3.0.0\n",
      "  Using cached google_cloud_dataproc-3.1.1-py2.py3-none-any.whl (186 kB)\n",
      "Collecting ipython<9,>=8\n",
      "  Downloading ipython-8.4.0-py3-none-any.whl (750 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m155.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets<8,>=7.6.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from apache-beam[interactive]) (7.7.1)\n",
      "Collecting timeloop<2,>=1.0.2\n",
      "  Using cached timeloop-1.0.2.tar.gz (2.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from facets-overview<2,>=1.0.0->apache-beam[interactive]) (1.2.4)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.28.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (1.32.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from grpcio<2,>=1.33.1->apache-beam[interactive]) (1.15.0)\n",
      "Requirement already satisfied: docopt in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[interactive]) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from httplib2<0.21.0,>=0.8->apache-beam[interactive]) (2.4.7)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel<7,>=6->apache-beam[interactive]) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.5.5)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel<7,>=6->apache-beam[interactive]) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.5.1)\n",
      "Requirement already satisfied: pickleshare in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (3.0.20)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (2.11.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipython<9,>=8->apache-beam[interactive]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.5->apache-beam[interactive]) (1.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.5->apache-beam[interactive]) (3.6.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jupyter-client<6.1.13,>=6.1.11->apache-beam[interactive]) (4.10.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jupyter-client<6.1.13,>=6.1.11->apache-beam[interactive]) (22.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[interactive]) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[interactive]) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[interactive]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[interactive]) (1.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=14.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (20.9)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (1.30.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (1.56.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jedi>=0.16->ipython<9,>=8->apache-beam[interactive]) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pexpect>4.3->ipython<9,>=8->apache-beam[interactive]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<9,>=8->apache-beam[interactive]) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (6.4.12)\n",
      "Requirement already satisfied: pure-eval in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from stack-data->ipython<9,>=8->apache-beam[interactive]) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from stack-data->ipython<9,>=8->apache-beam[interactive]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from stack-data->ipython<9,>=8->apache-beam[interactive]) (2.0.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (0.2.8)\n",
      "Requirement already satisfied: prometheus-client in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.14.1)\n",
      "Requirement already satisfied: nbformat in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (5.4.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (6.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (3.1.2)\n",
      "Requirement already satisfied: argon2-cffi in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.15.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (1.8.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.6.6)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (4.11.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.2.2)\n",
      "Requirement already satisfied: bleach in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (5.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (1.1.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (4.7.2)\n",
      "Requirement already satisfied: fastjsonschema in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (2.16.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-dataproc<3.2.0,>=3.0.0->apache-beam[interactive]) (0.4.8)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (21.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.18.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (1.14.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (2.3.2.post1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webencodings in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /home/padma/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.6.5->apache-beam[interactive]) (2.20)\n",
      "Building wheels for collected packages: timeloop\n",
      "  Building wheel for timeloop (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for timeloop: filename=timeloop-1.0.2-py3-none-any.whl size=3720 sha256=9935070b074aa55b65dff76b3191ac0cff40e2e8ba233b4b7defd367fca9f51a\n",
      "  Stored in directory: /home/padma/.cache/pip/wheels/63/47/01/8e48745e2b92e8a78dc988d4e9404e4f10ccdcd207dc0cad69\n",
      "Successfully built timeloop\n",
      "Installing collected packages: timeloop, jupyter-client, ipython, facets-overview, google-cloud-dataproc\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 7.2.2\n",
      "    Uninstalling jupyter-client-7.2.2:\n",
      "      Successfully uninstalled jupyter-client-7.2.2\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.34.0\n",
      "    Uninstalling ipython-7.34.0:\n",
      "      Successfully uninstalled ipython-7.34.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-model-analysis 0.40.0 requires ipython<8,>=7, but you have ipython 8.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed facets-overview-1.0.0 google-cloud-dataproc-3.1.1 ipython-8.4.0 jupyter-client-6.1.12 timeloop-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U apache-beam[interactive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDnPgN8UJtzN"
   },
   "source": [
    "Check the TensorFlow and TFX versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip <command> [options]\r\n",
      "\r\n",
      "no such option: -m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -m install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:10.428411Z",
     "iopub.status.busy": "2022-03-30T11:15:10.427809Z",
     "iopub.status.idle": "2022-03-30T11:15:14.989299Z",
     "shell.execute_reply": "2022-03-30T11:15:14.988701Z"
    },
    "id": "6jh7vKSRqPHb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "TFX version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDtLdSkvqPHe"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "There are some variables used to define a pipeline. You can customize these\n",
    "variables as you want. By default all output from the pipeline will be\n",
    "generated under the current directory. Instead of using the SchemaGen component to generate a schema, for this\n",
    "tutorial we will create a hardcoded schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:14.993088Z",
     "iopub.status.busy": "2022-03-30T11:15:14.992631Z",
     "iopub.status.idle": "2022-03-30T11:15:14.997768Z",
     "shell.execute_reply": "2022-03-30T11:15:14.997178Z"
    },
    "id": "EcUseqJaE2XN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PIPELINE_NAME = 'TFRS-ranking'\n",
    "\n",
    "# Directory where MovieLens 100K rating data lives\n",
    "DATA_ROOT = os.path.join('data', PIPELINE_NAME)\n",
    "# Output directory to store artifacts generated from the pipeline.\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "# Path to a SQLite DB file to use as an MLMD storage.\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "# Output directory where created models from the pipeline will be exported.\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F2SRwRLSYGa"
   },
   "source": [
    "### Prepare example data\n",
    "Since TFX does not currently support TensorFlow Datasets API, we will download the MovieLens 100K dataset manually for use in our TFX pipeline. The dataset we\n",
    "are using is\n",
    "[MovieLens 100K Dataset](https://grouplens.org/datasets/movielens/100k/).\n",
    "\n",
    "There are four numeric features in this dataset:\n",
    "\n",
    "- userId\n",
    "- movieId\n",
    "- rating\n",
    "- timestamp\n",
    "\n",
    "We will build a ranking model which predicts the `rating` of the movies. We will not use the `timestamp` feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11J7XiCq6AFP"
   },
   "source": [
    "Because TFX ExampleGen reads inputs from a directory, we need to create a\n",
    "directory and copy dataset to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:15.001220Z",
     "iopub.status.busy": "2022-03-30T11:15:15.000779Z",
     "iopub.status.idle": "2022-03-30T11:15:18.769769Z",
     "shell.execute_reply": "2022-03-30T11:15:18.768745Z"
    },
    "id": "4fxMs6u86acP"
   },
   "outputs": [],
   "source": [
    "# !wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "# !mkdir -p {DATA_ROOT}\n",
    "# !unzip ml-100k.zip\n",
    "# !echo 'username,ID,rating' > {DATA_ROOT}/ratings.csv\n",
    "# !sed 's/\\t/,/g' ml-100k/u.data >> {DATA_ROOT}/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASpoNmxKSQjI"
   },
   "source": [
    "Take a quick look at the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:18.774365Z",
     "iopub.status.busy": "2022-03-30T11:15:18.773811Z",
     "iopub.status.idle": "2022-03-30T11:15:18.897216Z",
     "shell.execute_reply": "2022-03-30T11:15:18.896505Z"
    },
    "id": "-eSz28UDSnlG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username,ID,rating,user_id\r\n",
      "akshaygahlot73,131689,2,284477248865\r\n",
      "akshaygahlot73,129692,6,284477248865\r\n",
      "akshaygahlot73,129689,7,284477248865\r\n",
      "akshaygahlot73,129052,4,284477248865\r\n",
      "akshaygahlot73,129130,7,284477248865\r\n",
      "akshaygahlot73,125932,1,284477248865\r\n",
      "akshaygahlot73,125529,4,284477248865\r\n",
      "akshaygahlot73,125526,10,284477248865\r\n",
      "akshaygahlot73,125523,7,284477248865\r\n"
     ]
    }
   ],
   "source": [
    "!head {DATA_ROOT}/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTtQNq1DdVvG"
   },
   "source": [
    "You should be able to see four values. For example, the first example means user '196' gives a rating of 3 to movie '242'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH6gizcpSwWV"
   },
   "source": [
    "## Create a pipeline\n",
    "\n",
    "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
    "consists of following three components.\n",
    "- CsvExampleGen: Reads in data files and convert them to TFX internal format\n",
    "for further processing. There are multiple\n",
    "[ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)s for various\n",
    "formats. In this tutorial, we will use CsvExampleGen which takes CSV file input.\n",
    "- Trainer: Trains an ML model.\n",
    "[Trainer component](https://www.tensorflow.org/tfx/guide/trainer) requires a\n",
    "model definition code from users. You can use TensorFlow APIs to specify how to\n",
    "train a model and save it in a _saved_model_ format.\n",
    "- Pusher: Copies the trained model outside of the TFX pipeline.\n",
    "[Pusher component](https://www.tensorflow.org/tfx/guide/pusher) can be thought\n",
    "of an deployment process of the trained ML model.\n",
    "\n",
    "Before actually define the pipeline, we need to write a model code for the\n",
    "Trainer component first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjDv93eS5xV"
   },
   "source": [
    "### Write model training code\n",
    "\n",
    "We will build a simple ranking model to predict movie ratings. This model training code will be saved to a separate file.\n",
    "\n",
    "In this tutorial we will use\n",
    "[Generic Trainer](https://www.tensorflow.org/tfx/guide/trainer#generic_trainer)\n",
    "of TFX which support Keras-based models. You need to write a Python file\n",
    "containing `run_fn` function, which is the entrypoint for the `Trainer`\n",
    "component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:18.901982Z",
     "iopub.status.busy": "2022-03-30T11:15:18.901404Z",
     "iopub.status.idle": "2022-03-30T11:15:18.905009Z",
     "shell.execute_reply": "2022-03-30T11:15:18.904303Z"
    },
    "id": "aES7Hv5QTDK3"
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'tfrs_ranking_trainer.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFsQCOytiidq"
   },
   "source": [
    "The ranking model we use is almost exactly the same as in the [Basic Ranking](https://www.tensorflow.org/recommenders/examples/basic_ranking) tutorial. The only difference is that we use movie IDs instead of movie titles in the candidate tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:18.908494Z",
     "iopub.status.busy": "2022-03-30T11:15:18.908293Z",
     "iopub.status.idle": "2022-03-30T11:15:18.915317Z",
     "shell.execute_reply": "2022-03-30T11:15:18.914518Z"
    },
    "id": "Gnc67uQNTDfW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tfrs_ranking_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "from typing import Dict, Text\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "_FEATURE_KEYS = ['user_id', 'ID']\n",
    "_LABEL_KEY = 'rating'\n",
    "\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "        for feature in _FEATURE_KEYS\n",
    "    }, _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "df = pd.read_csv('data/TFRS-ranking/ratings.csv')\n",
    "user_count = len(df['user_id'].unique())\n",
    "problem_count = len(df['ID'].unique())\n",
    "\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    unique_user_ids = np.array(range(user_count)).astype(str)\n",
    "    unique_problem_ids = np.array(range(problem_count)).astype(str)\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='user_id', dtype=tf.int64),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.as_string(x)),\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for problems.\n",
    "    self.problem_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='ID', dtype=tf.int64),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.as_string(x)),\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_problem_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_problem_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, problem_id = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    problem_embedding = self.problem_embeddings(problem_id)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, problem_embedding], axis=2))\n",
    "\n",
    "\n",
    "class problemlensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model((features['user_id'], features['ID']))\n",
    "\n",
    "  def compute_loss(self,\n",
    "                   features: Dict[Text, tf.Tensor],\n",
    "                   training=False) -> tf.Tensor:\n",
    "\n",
    "    labels = features[1]\n",
    "    rating_predictions = self(features[0])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int = 256) -> tf.data.Dataset:\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _build_keras_model() -> tf.keras.Model:\n",
    "  return problemlensModel()\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files, fn_args.data_accessor, schema, batch_size=8192)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files, fn_args.data_accessor, schema, batch_size=4096)\n",
    "\n",
    "  model = _build_keras_model()\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      epochs = 3,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  model.save(fn_args.serving_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blaw0rs-emEf"
   },
   "source": [
    "Now you have completed all preparation steps to build the TFX pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OkNz3gTLwM"
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We define a function to create a TFX pipeline. A `Pipeline` object\n",
    "represents a TFX pipeline which can be run using one of pipeline\n",
    "orchestration systems that TFX supports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:18.918786Z",
     "iopub.status.busy": "2022-03-30T11:15:18.918398Z",
     "iopub.status.idle": "2022-03-30T11:15:18.927702Z",
     "shell.execute_reply": "2022-03-30T11:15:18.926965Z"
    },
    "id": "M49yYVNBTPd4"
   },
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=12),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=24))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbq07THU2GV"
   },
   "source": [
    "## Run the pipeline\n",
    "\n",
    "TFX supports multiple orchestrators to run pipelines.\n",
    "In this tutorial we will use `LocalDagRunner` which is included in the TFX\n",
    "Python package and runs pipelines on local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mp0AkmrPdUb"
   },
   "source": [
    "Now we create a `LocalDagRunner` and pass a `Pipeline` object created from the\n",
    "function we already defined.\n",
    "\n",
    "The pipeline runs directly and you can see logs for the progress of the pipeline including ML model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:18.931155Z",
     "iopub.status.busy": "2022-03-30T11:15:18.930629Z",
     "iopub.status.idle": "2022-03-30T11:15:50.996929Z",
     "shell.execute_reply": "2022-03-30T11:15:50.996294Z"
    },
    "id": "fAtfOZTYWJu-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating ephemeral wheel package for '/home/padma/Desktop/Coderecs/tfrs_ranking_trainer.py' (including modules: ['tfrs_ranking_trainer']).\n",
      "INFO:absl:User module package has hash fingerprint version a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.\n",
      "INFO:absl:Executing: ['/home/padma/anaconda3/envs/tf_gpu/bin/python', '/tmp/tmp5ez91m6z/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmphigo297y', '--dist-dir', '/tmp/tmpxvgmqbg2']\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl'; target user module is 'tfrs_ranking_trainer'.\n",
      "INFO:absl:Full user module path is 'tfrs_ranking_trainer@pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl'\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Pusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Trainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"metadata/TFRS-ranking/metadata.db\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"metadata/TFRS-ranking/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data/TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying tfrs_ranking_trainer.py -> build/lib\n",
      "installing to /tmp/tmphigo297y\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/tfrs_ranking_trainer.py -> /tmp/tmphigo297y\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmphigo297y/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmphigo297y/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.dist-info/WHEEL\n",
      "creating '/tmp/tmpxvgmqbg2/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl' and adding '/tmp/tmphigo297y' to it\n",
      "adding 'tfrs_ranking_trainer.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932.dist-info/RECORD'\n",
      "removing /tmp/tmphigo297y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 1\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/CsvExampleGen/examples/1\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:153754296,xor_checksum:1658150224,sum_checksum:1658150224\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'input_base': 'data/TFRS-ranking', 'output_file_format': 5, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:153754296,xor_checksum:1658150224,sum_checksum:1658150224'}, execution_output_uri='pipelines/TFRS-ranking/CsvExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='pipelines/TFRS-ranking/CsvExampleGen/.system/stateful_working_dir/2022-07-18T18:47:40.001594', tmp_dir='pipelines/TFRS-ranking/CsvExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data/TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TFRS-ranking\"\n",
      ", pipeline_run_id='2022-07-18T18:47:40.001594')\n",
      "INFO:absl:Generating examples.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processing input csv data data/TFRS-ranking/* to TFExample.\n",
      "E0718 18:47:41.766136707   14645 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 1 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/CsvExampleGen/examples/1\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:153754296,xor_checksum:1658150224,sum_checksum:1658150224\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 1\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-18T18:47:40.001594\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 24\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tfrs_ranking_trainer@pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 12\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 2\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\n",
      "type_id: 15\n",
      "uri: \"pipelines/TFRS-ranking/CsvExampleGen/examples/1\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:153754296,xor_checksum:1658150224,sum_checksum:1658150224\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:CsvExampleGen:examples:0\"\n",
      "create_time_since_epoch: 1658150796197\n",
      "last_update_time_since_epoch: 1658150796197\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Trainer/model/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Trainer/model_run/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'module_path': 'tfrs_ranking_trainer@pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 12\\n}', 'eval_args': '{\\n  \"num_steps\": 24\\n}', 'custom_config': 'null'}, execution_output_uri='pipelines/TFRS-ranking/Trainer/.system/executor_execution/2/executor_output.pb', stateful_working_dir='pipelines/TFRS-ranking/Trainer/.system/stateful_working_dir/2022-07-18T18:47:40.001594', tmp_dir='pipelines/TFRS-ranking/Trainer/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-18T18:47:40.001594\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 24\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tfrs_ranking_trainer@pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 12\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TFRS-ranking\"\n",
      ", pipeline_run_id='2022-07-18T18:47:40.001594')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:udf_utils.get_fn {'module_path': 'tfrs_ranking_trainer@pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 12\\n}', 'eval_args': '{\\n  \"num_steps\": 24\\n}', 'custom_config': 'null'} 'run_fn'\n",
      "INFO:absl:Installing 'pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/padma/anaconda3/envs/tf_gpu/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmph9wnb5bd', 'pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl']\n",
      "E0718 18:56:36.618800029   14645 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipelines/TFRS-ranking/_wheels/tfx_user_code_Trainer-0.0+a316e354e9f0b2767a29ad95476ac0421c04d4b94e8a1208c15b8e9ad1b35932-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature ID has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "2022-07-18 18:56:39.647061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-18 18:56:40.215346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7071 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:65:00.0, compute capability: 6.1\n",
      "INFO:absl:Feature ID has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature ID has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature ID has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12/12 [==============================] - 6s 130ms/step - root_mean_squared_error: 3.9801 - loss: 15.4937 - regularization_loss: 0.0000e+00 - total_loss: 15.4937 - val_root_mean_squared_error: 3.1391 - val_loss: 9.1427 - val_regularization_loss: 0.0000e+00 - val_total_loss: 9.1427\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 1s 87ms/step - root_mean_squared_error: 3.1544 - loss: 9.8621 - regularization_loss: 0.0000e+00 - total_loss: 9.8621 - val_root_mean_squared_error: 3.1506 - val_loss: 8.8569 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.8569\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 2s 137ms/step - root_mean_squared_error: 3.0255 - loss: 9.2010 - regularization_loss: 0.0000e+00 - total_loss: 9.2010 - val_root_mean_squared_error: 3.1192 - val_loss: 8.9075 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.9075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) ID with unsupported characters which will be renamed to id in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ranking_layer_call_fn, ranking_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/TFRS-ranking/Trainer/model/2/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines/TFRS-ranking/Trainer/model/2/Format-Serving/assets\n",
      "INFO:absl:Training complete. Model written to pipelines/TFRS-ranking/Trainer/model/2/Format-Serving. ModelRun written to pipelines/TFRS-ranking/Trainer/model_run/2\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 2 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Trainer/model/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Trainer/model_run/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 2\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-18T18:47:40.001594\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/TFRS-ranking\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 3\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'model': [Artifact(artifact: id: 2\n",
      "type_id: 17\n",
      "uri: \"pipelines/TFRS-ranking/Trainer/model/2\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Trainer:model:0\"\n",
      "create_time_since_epoch: 1658150810440\n",
      "last_update_time_since_epoch: 1658150810440\n",
      ", artifact_type: id: 17\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Pusher/pushed_model/3\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model/TFRS-ranking\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='pipelines/TFRS-ranking/Pusher/.system/executor_execution/3/executor_output.pb', stateful_working_dir='pipelines/TFRS-ranking/Pusher/.system/stateful_working_dir/2022-07-18T18:47:40.001594', tmp_dir='pipelines/TFRS-ranking/Pusher/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-18T18:47:40.001594\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TFRS-ranking.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-18T18:47:40.001594\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TFRS-ranking.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/TFRS-ranking\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TFRS-ranking\"\n",
      ", pipeline_run_id='2022-07-18T18:47:40.001594')\n",
      "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n",
      "INFO:absl:Model version: 1658150810\n",
      "INFO:absl:Model written to serving path serving_model/TFRS-ranking/1658150810.\n",
      "INFO:absl:Model pushed to pipelines/TFRS-ranking/Pusher/pushed_model/3.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 3 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/TFRS-ranking/Pusher/pushed_model/3\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"TFRS-ranking:2022-07-18T18:47:40.001594:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.9.0\"\n",
      "  }\n",
      "}\n",
      "name: \"TFRS-ranking:2022-07-18T18:47:40.001594:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "tfx.orchestration.LocalDagRunner().run(\n",
    "  _create_pipeline(\n",
    "      pipeline_name=PIPELINE_NAME,\n",
    "      pipeline_root=PIPELINE_ROOT,\n",
    "      data_root=DATA_ROOT,\n",
    "      module_file=_trainer_module_file,\n",
    "      serving_model_dir=SERVING_MODEL_DIR,\n",
    "      metadata_path=METADATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppERq0Mj6xvW"
   },
   "source": [
    "You should see \"INFO:absl:Component Pusher is finished.\" at the end of the\n",
    "logs if the pipeline finished successfully. Because `Pusher` component is the\n",
    "last component of the pipeline.\n",
    "\n",
    "The pusher component pushes the trained model to the `SERVING_MODEL_DIR` which\n",
    "is the `serving_model/TFRS-ranking` directory if you did not change the\n",
    "variables in the previous steps. You can see the result from the file browser\n",
    "in the left-side panel in Colab, or using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:51.000648Z",
     "iopub.status.busy": "2022-03-30T11:15:51.000090Z",
     "iopub.status.idle": "2022-03-30T11:15:51.150519Z",
     "shell.execute_reply": "2022-03-30T11:15:51.149729Z"
    },
    "id": "NTHROkqX6yHx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m1654925577\u001b[m\u001b[m \u001b[34m1655570863\u001b[m\u001b[m\n",
      "\n",
      "serving_model/TFRS-ranking/1654925577:\n",
      "\u001b[34massets\u001b[m\u001b[m            keras_metadata.pb saved_model.pbtxt \u001b[34mvariables\u001b[m\u001b[m\n",
      "\n",
      "serving_model/TFRS-ranking/1654925577/assets:\n",
      "\n",
      "serving_model/TFRS-ranking/1654925577/variables:\n",
      "variables.data-00000-of-00001 variables.index\n",
      "\n",
      "serving_model/TFRS-ranking/1655570863:\n",
      "\u001b[34massets\u001b[m\u001b[m            keras_metadata.pb saved_model.pb    \u001b[34mvariables\u001b[m\u001b[m\n",
      "\n",
      "serving_model/TFRS-ranking/1655570863/assets:\n",
      "\n",
      "serving_model/TFRS-ranking/1655570863/variables:\n",
      "variables.data-00000-of-00001 variables.index\n"
     ]
    }
   ],
   "source": [
    "# List files in created model directory.\n",
    "!ls -R {SERVING_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m489.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m80.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (39.0.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[12 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m     from setuptools.dist import Distribution, Feature\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/setuptools/dist.py\", line 24, in <module>\n",
      "  \u001b[31m   \u001b[0m     from setuptools.depends import Require\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/setuptools/depends.py\", line 7, in <module>\n",
      "  \u001b[31m   \u001b[0m     from .py33compat import Bytecode\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/setuptools/py33compat.py\", line 54, in <module>\n",
      "  \u001b[31m   \u001b[0m     unescape = getattr(html, 'unescape', html_parser.HTMLParser().unescape)\n",
      "  \u001b[31m   \u001b[0m AttributeError: 'HTMLParser' object has no attribute 'unescape'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8HQfT-ziids"
   },
   "source": [
    "Now we can test the ranking model by computing predictions for a user and a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T11:15:51.155091Z",
     "iopub.status.busy": "2022-03-30T11:15:51.154530Z",
     "iopub.status.idle": "2022-03-30T11:15:52.202316Z",
     "shell.execute_reply": "2022-03-30T11:15:52.201647Z"
    },
    "id": "5EDMkz8Wiidt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.7295794]]]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Load the latest model for testing\n",
    "loaded = tf.saved_model.load(max(glob.glob(os.path.join(SERVING_MODEL_DIR, '*/')), key=os.path.getmtime))\n",
    "print(loaded({'user_id': [[1291971074983]], 'ID': [[132332]]}).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08R8qvweThRf"
   },
   "source": [
    "This concludes the TensorFlow Recommenders + TFX tutorial."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DjUA6S30k52h"
   ],
   "name": "ranking_tfx.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "1890c4b2171dd355a54cfbb3b64afc2ee5538b719915483f93bdc6de79852a20"
  },
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
